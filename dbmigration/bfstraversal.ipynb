{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\python38\\lib\\site-packages (2.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\mario\\appdata\\roaming\\python\\python38\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\python38\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\python38\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.20.3 in c:\\python38\\lib\\site-packages (from pandas) (1.24.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\mario\\appdata\\roaming\\python\\python38\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: sqlalchemy in c:\\python38\\lib\\site-packages (2.0.23)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\mario\\appdata\\roaming\\python\\python38\\site-packages (from sqlalchemy) (4.8.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\python38\\lib\\site-packages (from sqlalchemy) (3.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "ename": "OperationalError",
     "evalue": "(psycopg2.OperationalError) could not translate host name \"default_host\" to address: No such host is known. \n\n(Background on this error at: https://sqlalche.me/e/20/e3q8)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Python38\\lib\\site-packages\\sqlalchemy\\engine\\base.py:145\u001b[0m, in \u001b[0;36mConnection.__init__\u001b[1;34m(self, engine, connection, _has_events, _allow_revalidate, _allow_autobegin)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 145\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dbapi_connection \u001b[39m=\u001b[39m engine\u001b[39m.\u001b[39;49mraw_connection()\n\u001b[0;32m    146\u001b[0m \u001b[39mexcept\u001b[39;00m dialect\u001b[39m.\u001b[39mloaded_dbapi\u001b[39m.\u001b[39mError \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Python38\\lib\\site-packages\\sqlalchemy\\engine\\base.py:3292\u001b[0m, in \u001b[0;36mEngine.raw_connection\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   3271\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Return a \"raw\" DBAPI connection from the connection pool.\u001b[39;00m\n\u001b[0;32m   3272\u001b[0m \n\u001b[0;32m   3273\u001b[0m \u001b[39mThe returned object is a proxied version of the DBAPI\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3290\u001b[0m \n\u001b[0;32m   3291\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m-> 3292\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpool\u001b[39m.\u001b[39;49mconnect()\n",
      "File \u001b[1;32mc:\\Python38\\lib\\site-packages\\sqlalchemy\\pool\\base.py:452\u001b[0m, in \u001b[0;36mPool.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    445\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Return a DBAPI connection from the pool.\u001b[39;00m\n\u001b[0;32m    446\u001b[0m \n\u001b[0;32m    447\u001b[0m \u001b[39mThe connection is instrumented such that when its\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    450\u001b[0m \n\u001b[0;32m    451\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 452\u001b[0m \u001b[39mreturn\u001b[39;00m _ConnectionFairy\u001b[39m.\u001b[39;49m_checkout(\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Python38\\lib\\site-packages\\sqlalchemy\\pool\\base.py:1269\u001b[0m, in \u001b[0;36m_ConnectionFairy._checkout\u001b[1;34m(cls, pool, threadconns, fairy)\u001b[0m\n\u001b[0;32m   1268\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m fairy:\n\u001b[1;32m-> 1269\u001b[0m     fairy \u001b[39m=\u001b[39m _ConnectionRecord\u001b[39m.\u001b[39;49mcheckout(pool)\n\u001b[0;32m   1271\u001b[0m     \u001b[39mif\u001b[39;00m threadconns \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Python38\\lib\\site-packages\\sqlalchemy\\pool\\base.py:716\u001b[0m, in \u001b[0;36m_ConnectionRecord.checkout\u001b[1;34m(cls, pool)\u001b[0m\n\u001b[0;32m    715\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 716\u001b[0m     rec \u001b[39m=\u001b[39m pool\u001b[39m.\u001b[39;49m_do_get()\n\u001b[0;32m    718\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Python38\\lib\\site-packages\\sqlalchemy\\pool\\impl.py:170\u001b[0m, in \u001b[0;36mQueuePool._do_get\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[39mwith\u001b[39;00m util\u001b[39m.\u001b[39msafe_reraise():\n\u001b[1;32m--> 170\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dec_overflow()\n\u001b[0;32m    171\u001b[0m \u001b[39mraise\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python38\\lib\\site-packages\\sqlalchemy\\util\\langhelpers.py:146\u001b[0m, in \u001b[0;36msafe_reraise.__exit__\u001b[1;34m(self, type_, value, traceback)\u001b[0m\n\u001b[0;32m    145\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exc_info \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m  \u001b[39m# remove potential circular references\u001b[39;00m\n\u001b[1;32m--> 146\u001b[0m     \u001b[39mraise\u001b[39;00m exc_value\u001b[39m.\u001b[39mwith_traceback(exc_tb)\n\u001b[0;32m    147\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Python38\\lib\\site-packages\\sqlalchemy\\pool\\impl.py:167\u001b[0m, in \u001b[0;36mQueuePool._do_get\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 167\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_connection()\n\u001b[0;32m    168\u001b[0m \u001b[39mexcept\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Python38\\lib\\site-packages\\sqlalchemy\\pool\\base.py:393\u001b[0m, in \u001b[0;36mPool._create_connection\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    391\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Called by subclasses to create a new ConnectionRecord.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 393\u001b[0m \u001b[39mreturn\u001b[39;00m _ConnectionRecord(\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Python38\\lib\\site-packages\\sqlalchemy\\pool\\base.py:678\u001b[0m, in \u001b[0;36m_ConnectionRecord.__init__\u001b[1;34m(self, pool, connect)\u001b[0m\n\u001b[0;32m    677\u001b[0m \u001b[39mif\u001b[39;00m connect:\n\u001b[1;32m--> 678\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__connect()\n\u001b[0;32m    679\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfinalize_callback \u001b[39m=\u001b[39m deque()\n",
      "File \u001b[1;32mc:\\Python38\\lib\\site-packages\\sqlalchemy\\pool\\base.py:903\u001b[0m, in \u001b[0;36m_ConnectionRecord.__connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    902\u001b[0m     \u001b[39mwith\u001b[39;00m util\u001b[39m.\u001b[39msafe_reraise():\n\u001b[1;32m--> 903\u001b[0m         pool\u001b[39m.\u001b[39mlogger\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mError on connect(): \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, e)\n\u001b[0;32m    904\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    905\u001b[0m     \u001b[39m# in SQLAlchemy 1.4 the first_connect event is not used by\u001b[39;00m\n\u001b[0;32m    906\u001b[0m     \u001b[39m# the engine, so this will usually not be set\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python38\\lib\\site-packages\\sqlalchemy\\util\\langhelpers.py:146\u001b[0m, in \u001b[0;36msafe_reraise.__exit__\u001b[1;34m(self, type_, value, traceback)\u001b[0m\n\u001b[0;32m    145\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exc_info \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m  \u001b[39m# remove potential circular references\u001b[39;00m\n\u001b[1;32m--> 146\u001b[0m     \u001b[39mraise\u001b[39;00m exc_value\u001b[39m.\u001b[39mwith_traceback(exc_tb)\n\u001b[0;32m    147\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Python38\\lib\\site-packages\\sqlalchemy\\pool\\base.py:898\u001b[0m, in \u001b[0;36m_ConnectionRecord.__connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    897\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstarttime \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m--> 898\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdbapi_connection \u001b[39m=\u001b[39m connection \u001b[39m=\u001b[39m pool\u001b[39m.\u001b[39;49m_invoke_creator(\u001b[39mself\u001b[39;49m)\n\u001b[0;32m    899\u001b[0m pool\u001b[39m.\u001b[39mlogger\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mCreated new connection \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m, connection)\n",
      "File \u001b[1;32mc:\\Python38\\lib\\site-packages\\sqlalchemy\\engine\\create.py:637\u001b[0m, in \u001b[0;36mcreate_engine.<locals>.connect\u001b[1;34m(connection_record)\u001b[0m\n\u001b[0;32m    635\u001b[0m             \u001b[39mreturn\u001b[39;00m connection\n\u001b[1;32m--> 637\u001b[0m \u001b[39mreturn\u001b[39;00m dialect\u001b[39m.\u001b[39;49mconnect(\u001b[39m*\u001b[39;49mcargs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcparams)\n",
      "File \u001b[1;32mc:\\Python38\\lib\\site-packages\\sqlalchemy\\engine\\default.py:616\u001b[0m, in \u001b[0;36mDefaultDialect.connect\u001b[1;34m(self, *cargs, **cparams)\u001b[0m\n\u001b[0;32m    614\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconnect\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39mcargs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcparams):\n\u001b[0;32m    615\u001b[0m     \u001b[39m# inherits the docstring from interfaces.Dialect.connect\u001b[39;00m\n\u001b[1;32m--> 616\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloaded_dbapi\u001b[39m.\u001b[39;49mconnect(\u001b[39m*\u001b[39;49mcargs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcparams)\n",
      "File \u001b[1;32mc:\\Python38\\lib\\site-packages\\psycopg2\\__init__.py:122\u001b[0m, in \u001b[0;36mconnect\u001b[1;34m(dsn, connection_factory, cursor_factory, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m dsn \u001b[39m=\u001b[39m _ext\u001b[39m.\u001b[39mmake_dsn(dsn, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 122\u001b[0m conn \u001b[39m=\u001b[39m _connect(dsn, connection_factory\u001b[39m=\u001b[39;49mconnection_factory, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwasync)\n\u001b[0;32m    123\u001b[0m \u001b[39mif\u001b[39;00m cursor_factory \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mOperationalError\u001b[0m: could not translate host name \"default_host\" to address: No such host is known. \n",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\mario\\Desktop\\LaMin\\Projects\\ProjectX\\dbmigration\\bfstraversal.ipynb Cell 1\u001b[0m line \u001b[0;36m8\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mario/Desktop/LaMin/Projects/ProjectX/dbmigration/bfstraversal.ipynb#W0sZmlsZQ%3D%3D?line=85'>86</a>\u001b[0m default_json \u001b[39m=\u001b[39m {}  \u001b[39m# Update this with a suitable default JSON object\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mario/Desktop/LaMin/Projects/ProjectX/dbmigration/bfstraversal.ipynb#W0sZmlsZQ%3D%3D?line=86'>87</a>\u001b[0m empty_placeholder \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mN\u001b[39m\u001b[39m\"\u001b[39m  \u001b[39m# Placeholder for empty fields in .dump file\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/mario/Desktop/LaMin/Projects/ProjectX/dbmigration/bfstraversal.ipynb#W0sZmlsZQ%3D%3D?line=88'>89</a>\u001b[0m \u001b[39mwith\u001b[39;00m engine\u001b[39m.\u001b[39;49mconnect() \u001b[39mas\u001b[39;00m conn:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mario/Desktop/LaMin/Projects/ProjectX/dbmigration/bfstraversal.ipynb#W0sZmlsZQ%3D%3D?line=89'>90</a>\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mSuccessfully connected to the database!\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mario/Desktop/LaMin/Projects/ProjectX/dbmigration/bfstraversal.ipynb#W0sZmlsZQ%3D%3D?line=90'>91</a>\u001b[0m         conn\u001b[39m.\u001b[39mexecute(text(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSET search_path TO \u001b[39m\u001b[39m{\u001b[39;00mschema_name\u001b[39m}\u001b[39;00m\u001b[39m;\u001b[39m\u001b[39m\"\u001b[39m))\n",
      "File \u001b[1;32mc:\\Python38\\lib\\site-packages\\sqlalchemy\\engine\\base.py:3268\u001b[0m, in \u001b[0;36mEngine.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   3245\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconnect\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Connection:\n\u001b[0;32m   3246\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Return a new :class:`_engine.Connection` object.\u001b[39;00m\n\u001b[0;32m   3247\u001b[0m \n\u001b[0;32m   3248\u001b[0m \u001b[39m    The :class:`_engine.Connection` acts as a Python context manager, so\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3265\u001b[0m \n\u001b[0;32m   3266\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 3268\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_connection_cls(\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Python38\\lib\\site-packages\\sqlalchemy\\engine\\base.py:147\u001b[0m, in \u001b[0;36mConnection.__init__\u001b[1;34m(self, engine, connection, _has_events, _allow_revalidate, _allow_autobegin)\u001b[0m\n\u001b[0;32m    145\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dbapi_connection \u001b[39m=\u001b[39m engine\u001b[39m.\u001b[39mraw_connection()\n\u001b[0;32m    146\u001b[0m     \u001b[39mexcept\u001b[39;00m dialect\u001b[39m.\u001b[39mloaded_dbapi\u001b[39m.\u001b[39mError \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m--> 147\u001b[0m         Connection\u001b[39m.\u001b[39;49m_handle_dbapi_exception_noconnection(\n\u001b[0;32m    148\u001b[0m             err, dialect, engine\n\u001b[0;32m    149\u001b[0m         )\n\u001b[0;32m    150\u001b[0m         \u001b[39mraise\u001b[39;00m\n\u001b[0;32m    151\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Python38\\lib\\site-packages\\sqlalchemy\\engine\\base.py:2430\u001b[0m, in \u001b[0;36mConnection._handle_dbapi_exception_noconnection\u001b[1;34m(cls, e, dialect, engine, is_disconnect, invalidate_pool_on_disconnect, is_pre_ping)\u001b[0m\n\u001b[0;32m   2428\u001b[0m \u001b[39melif\u001b[39;00m should_wrap:\n\u001b[0;32m   2429\u001b[0m     \u001b[39massert\u001b[39;00m sqlalchemy_exception \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 2430\u001b[0m     \u001b[39mraise\u001b[39;00m sqlalchemy_exception\u001b[39m.\u001b[39mwith_traceback(exc_info[\u001b[39m2\u001b[39m]) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[0;32m   2431\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2432\u001b[0m     \u001b[39massert\u001b[39;00m exc_info[\u001b[39m1\u001b[39m] \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python38\\lib\\site-packages\\sqlalchemy\\engine\\base.py:145\u001b[0m, in \u001b[0;36mConnection.__init__\u001b[1;34m(self, engine, connection, _has_events, _allow_revalidate, _allow_autobegin)\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[39mif\u001b[39;00m connection \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    144\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 145\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dbapi_connection \u001b[39m=\u001b[39m engine\u001b[39m.\u001b[39;49mraw_connection()\n\u001b[0;32m    146\u001b[0m     \u001b[39mexcept\u001b[39;00m dialect\u001b[39m.\u001b[39mloaded_dbapi\u001b[39m.\u001b[39mError \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m    147\u001b[0m         Connection\u001b[39m.\u001b[39m_handle_dbapi_exception_noconnection(\n\u001b[0;32m    148\u001b[0m             err, dialect, engine\n\u001b[0;32m    149\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Python38\\lib\\site-packages\\sqlalchemy\\engine\\base.py:3292\u001b[0m, in \u001b[0;36mEngine.raw_connection\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   3270\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mraw_connection\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m PoolProxiedConnection:\n\u001b[0;32m   3271\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Return a \"raw\" DBAPI connection from the connection pool.\u001b[39;00m\n\u001b[0;32m   3272\u001b[0m \n\u001b[0;32m   3273\u001b[0m \u001b[39m    The returned object is a proxied version of the DBAPI\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3290\u001b[0m \n\u001b[0;32m   3291\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 3292\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpool\u001b[39m.\u001b[39;49mconnect()\n",
      "File \u001b[1;32mc:\\Python38\\lib\\site-packages\\sqlalchemy\\pool\\base.py:452\u001b[0m, in \u001b[0;36mPool.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    444\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconnect\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m PoolProxiedConnection:\n\u001b[0;32m    445\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Return a DBAPI connection from the pool.\u001b[39;00m\n\u001b[0;32m    446\u001b[0m \n\u001b[0;32m    447\u001b[0m \u001b[39m    The connection is instrumented such that when its\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    450\u001b[0m \n\u001b[0;32m    451\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 452\u001b[0m     \u001b[39mreturn\u001b[39;00m _ConnectionFairy\u001b[39m.\u001b[39;49m_checkout(\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Python38\\lib\\site-packages\\sqlalchemy\\pool\\base.py:1269\u001b[0m, in \u001b[0;36m_ConnectionFairy._checkout\u001b[1;34m(cls, pool, threadconns, fairy)\u001b[0m\n\u001b[0;32m   1261\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[0;32m   1262\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_checkout\u001b[39m(\n\u001b[0;32m   1263\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1266\u001b[0m     fairy: Optional[_ConnectionFairy] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   1267\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m _ConnectionFairy:\n\u001b[0;32m   1268\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m fairy:\n\u001b[1;32m-> 1269\u001b[0m         fairy \u001b[39m=\u001b[39m _ConnectionRecord\u001b[39m.\u001b[39;49mcheckout(pool)\n\u001b[0;32m   1271\u001b[0m         \u001b[39mif\u001b[39;00m threadconns \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1272\u001b[0m             threadconns\u001b[39m.\u001b[39mcurrent \u001b[39m=\u001b[39m weakref\u001b[39m.\u001b[39mref(fairy)\n",
      "File \u001b[1;32mc:\\Python38\\lib\\site-packages\\sqlalchemy\\pool\\base.py:716\u001b[0m, in \u001b[0;36m_ConnectionRecord.checkout\u001b[1;34m(cls, pool)\u001b[0m\n\u001b[0;32m    714\u001b[0m     rec \u001b[39m=\u001b[39m cast(_ConnectionRecord, pool\u001b[39m.\u001b[39m_do_get())\n\u001b[0;32m    715\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 716\u001b[0m     rec \u001b[39m=\u001b[39m pool\u001b[39m.\u001b[39;49m_do_get()\n\u001b[0;32m    718\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    719\u001b[0m     dbapi_connection \u001b[39m=\u001b[39m rec\u001b[39m.\u001b[39mget_connection()\n",
      "File \u001b[1;32mc:\\Python38\\lib\\site-packages\\sqlalchemy\\pool\\impl.py:170\u001b[0m, in \u001b[0;36mQueuePool._do_get\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    168\u001b[0m     \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m    169\u001b[0m         \u001b[39mwith\u001b[39;00m util\u001b[39m.\u001b[39msafe_reraise():\n\u001b[1;32m--> 170\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dec_overflow()\n\u001b[0;32m    171\u001b[0m         \u001b[39mraise\u001b[39;00m\n\u001b[0;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Python38\\lib\\site-packages\\sqlalchemy\\util\\langhelpers.py:146\u001b[0m, in \u001b[0;36msafe_reraise.__exit__\u001b[1;34m(self, type_, value, traceback)\u001b[0m\n\u001b[0;32m    144\u001b[0m     \u001b[39massert\u001b[39;00m exc_value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    145\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exc_info \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m  \u001b[39m# remove potential circular references\u001b[39;00m\n\u001b[1;32m--> 146\u001b[0m     \u001b[39mraise\u001b[39;00m exc_value\u001b[39m.\u001b[39mwith_traceback(exc_tb)\n\u001b[0;32m    147\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exc_info \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m  \u001b[39m# remove potential circular references\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python38\\lib\\site-packages\\sqlalchemy\\pool\\impl.py:167\u001b[0m, in \u001b[0;36mQueuePool._do_get\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inc_overflow():\n\u001b[0;32m    166\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 167\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_connection()\n\u001b[0;32m    168\u001b[0m     \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m    169\u001b[0m         \u001b[39mwith\u001b[39;00m util\u001b[39m.\u001b[39msafe_reraise():\n",
      "File \u001b[1;32mc:\\Python38\\lib\\site-packages\\sqlalchemy\\pool\\base.py:393\u001b[0m, in \u001b[0;36mPool._create_connection\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    390\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_create_connection\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ConnectionPoolEntry:\n\u001b[0;32m    391\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Called by subclasses to create a new ConnectionRecord.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 393\u001b[0m     \u001b[39mreturn\u001b[39;00m _ConnectionRecord(\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Python38\\lib\\site-packages\\sqlalchemy\\pool\\base.py:678\u001b[0m, in \u001b[0;36m_ConnectionRecord.__init__\u001b[1;34m(self, pool, connect)\u001b[0m\n\u001b[0;32m    676\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__pool \u001b[39m=\u001b[39m pool\n\u001b[0;32m    677\u001b[0m \u001b[39mif\u001b[39;00m connect:\n\u001b[1;32m--> 678\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__connect()\n\u001b[0;32m    679\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfinalize_callback \u001b[39m=\u001b[39m deque()\n",
      "File \u001b[1;32mc:\\Python38\\lib\\site-packages\\sqlalchemy\\pool\\base.py:903\u001b[0m, in \u001b[0;36m_ConnectionRecord.__connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    901\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    902\u001b[0m     \u001b[39mwith\u001b[39;00m util\u001b[39m.\u001b[39msafe_reraise():\n\u001b[1;32m--> 903\u001b[0m         pool\u001b[39m.\u001b[39mlogger\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mError on connect(): \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, e)\n\u001b[0;32m    904\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    905\u001b[0m     \u001b[39m# in SQLAlchemy 1.4 the first_connect event is not used by\u001b[39;00m\n\u001b[0;32m    906\u001b[0m     \u001b[39m# the engine, so this will usually not be set\u001b[39;00m\n\u001b[0;32m    907\u001b[0m     \u001b[39mif\u001b[39;00m pool\u001b[39m.\u001b[39mdispatch\u001b[39m.\u001b[39mfirst_connect:\n",
      "File \u001b[1;32mc:\\Python38\\lib\\site-packages\\sqlalchemy\\util\\langhelpers.py:146\u001b[0m, in \u001b[0;36msafe_reraise.__exit__\u001b[1;34m(self, type_, value, traceback)\u001b[0m\n\u001b[0;32m    144\u001b[0m     \u001b[39massert\u001b[39;00m exc_value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    145\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exc_info \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m  \u001b[39m# remove potential circular references\u001b[39;00m\n\u001b[1;32m--> 146\u001b[0m     \u001b[39mraise\u001b[39;00m exc_value\u001b[39m.\u001b[39mwith_traceback(exc_tb)\n\u001b[0;32m    147\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exc_info \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m  \u001b[39m# remove potential circular references\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python38\\lib\\site-packages\\sqlalchemy\\pool\\base.py:898\u001b[0m, in \u001b[0;36m_ConnectionRecord.__connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    896\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    897\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstarttime \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m--> 898\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdbapi_connection \u001b[39m=\u001b[39m connection \u001b[39m=\u001b[39m pool\u001b[39m.\u001b[39;49m_invoke_creator(\u001b[39mself\u001b[39;49m)\n\u001b[0;32m    899\u001b[0m     pool\u001b[39m.\u001b[39mlogger\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mCreated new connection \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m, connection)\n\u001b[0;32m    900\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfresh \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python38\\lib\\site-packages\\sqlalchemy\\engine\\create.py:637\u001b[0m, in \u001b[0;36mcreate_engine.<locals>.connect\u001b[1;34m(connection_record)\u001b[0m\n\u001b[0;32m    634\u001b[0m         \u001b[39mif\u001b[39;00m connection \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    635\u001b[0m             \u001b[39mreturn\u001b[39;00m connection\n\u001b[1;32m--> 637\u001b[0m \u001b[39mreturn\u001b[39;00m dialect\u001b[39m.\u001b[39;49mconnect(\u001b[39m*\u001b[39;49mcargs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcparams)\n",
      "File \u001b[1;32mc:\\Python38\\lib\\site-packages\\sqlalchemy\\engine\\default.py:616\u001b[0m, in \u001b[0;36mDefaultDialect.connect\u001b[1;34m(self, *cargs, **cparams)\u001b[0m\n\u001b[0;32m    614\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconnect\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39mcargs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcparams):\n\u001b[0;32m    615\u001b[0m     \u001b[39m# inherits the docstring from interfaces.Dialect.connect\u001b[39;00m\n\u001b[1;32m--> 616\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloaded_dbapi\u001b[39m.\u001b[39;49mconnect(\u001b[39m*\u001b[39;49mcargs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcparams)\n",
      "File \u001b[1;32mc:\\Python38\\lib\\site-packages\\psycopg2\\__init__.py:122\u001b[0m, in \u001b[0;36mconnect\u001b[1;34m(dsn, connection_factory, cursor_factory, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     kwasync[\u001b[39m'\u001b[39m\u001b[39masync_\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m'\u001b[39m\u001b[39masync_\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    121\u001b[0m dsn \u001b[39m=\u001b[39m _ext\u001b[39m.\u001b[39mmake_dsn(dsn, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 122\u001b[0m conn \u001b[39m=\u001b[39m _connect(dsn, connection_factory\u001b[39m=\u001b[39;49mconnection_factory, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwasync)\n\u001b[0;32m    123\u001b[0m \u001b[39mif\u001b[39;00m cursor_factory \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     conn\u001b[39m.\u001b[39mcursor_factory \u001b[39m=\u001b[39m cursor_factory\n",
      "\u001b[1;31mOperationalError\u001b[0m: (psycopg2.OperationalError) could not translate host name \"default_host\" to address: No such host is known. \n\n(Background on this error at: https://sqlalche.me/e/20/e3q8)"
     ]
    }
   ],
   "source": [
    "%pip install pandas\n",
    "%pip install sqlalchemy\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "import io\n",
    "import csv\n",
    "import json\n",
    "import datetime\n",
    "import decimal\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine, MetaData, inspect, event, text\n",
    "from collections import deque\n",
    "from queue import Queue\n",
    "from collections import deque\n",
    "\n",
    "import pandas as pd\n",
    "# Database connection parameters\n",
    "# Database connection parameters are now retrieved from environment variables\n",
    "db_params = {\n",
    "    'host': os.getenv('DB_HOST', 'default_host'),\n",
    "    'dbname': os.getenv('DB_NAME', 'default_db_name'),\n",
    "    'user': os.getenv('DB_USER', 'default_user'),\n",
    "    'password': os.getenv('DB_PASSWORD', 'default_password'),\n",
    "    'port': int(os.getenv('DB_PORT', '5432'))  # Default port number if not specified\n",
    "}\n",
    "\n",
    "def get_table_columns(engine, schema_name, table_name, excluded_columns):\n",
    "    \"\"\"\n",
    "    Retrieve column names for a given table excluding certain columns.\n",
    "    \"\"\"\n",
    "    query = sqlalchemy.text(\"\"\"\n",
    "        SELECT column_name \n",
    "        FROM information_schema.columns \n",
    "        WHERE table_schema = :schema_name AND table_name = :table_name;\n",
    "    \"\"\")\n",
    "\n",
    "    with engine.connect() as conn:\n",
    "        result = conn.execute(query, {'schema_name': schema_name, 'table_name': table_name})\n",
    "        columns = [row[0] for row in result.fetchall() if row[0] not in excluded_columns]\n",
    "    \n",
    "    return columns\n",
    "def construct_select_clause(schema_name, table_name, columns):\n",
    "    \"\"\"\n",
    "    Construct a SELECT clause for a given table.\n",
    "    \"\"\"\n",
    "    return ', '.join([f'\"{schema_name}\".\"{table_name}\".\"{col}\"' for col in columns])\n",
    "\n",
    "# Adjusted construct_join_query function\n",
    "# Adjusted construct_join_query function\n",
    "# Adjusted construct_join_query function to include previous joins and where clause\n",
    "def construct_join_query(schema_name, starting_table, joined_table, starting_table_column, joined_table_column, key_value, previous_joins, where_clause):\n",
    "    \"\"\"\n",
    "    Construct a full JOIN query with all columns from the joined table, incorporating the schema name, previous joins, and where clause.\n",
    "    Ensure each table is only joined once.\n",
    "    \"\"\"\n",
    "    # Construct the new join condition\n",
    "    new_join_condition = f'LEFT JOIN \\\"{schema_name}\\\".\\\"{joined_table}\\\" ON \\\"{schema_name}\\\".\\\"{starting_table}\\\".\\\"{starting_table_column}\\\" = \\\"{schema_name}\\\".\\\"{joined_table}\\\".\\\"{joined_table_column}\\\"'\n",
    "    \n",
    "    # Combine previous joins with the new join condition\n",
    "    combined_joins = f\"{previous_joins} {new_join_condition}\"\n",
    "\n",
    "    # Construct the full join query string\n",
    "    full_join_query_str = f\"SELECT DISTINCT \\\"{schema_name}\\\".\\\"{joined_table}\\\".* FROM \\\"{schema_name}\\\".\\\"{starting_table}\\\" {combined_joins} {where_clause}\"\n",
    "    return text(full_join_query_str)\n",
    "# Establishing the connection\n",
    "db_url = f\"postgresql+psycopg2://{db_params['user']}:{db_params['password']}@{db_params['host']}:{db_params['port']}/{db_params['dbname']}\"\n",
    "engine = create_engine(db_url)\n",
    "\n",
    "       \n",
    "    \n",
    "\n",
    "# Set the schema for this session\n",
    "schema_name = os.getenv('DB_SCHEMA', 'default_schema')  # Retrieve schema name from environment variable\n",
    "\n",
    "@event.listens_for(engine, \"connect\")\n",
    "def set_search_path(dbapi_connection, connection_record):\n",
    "    cursor = dbapi_connection.cursor()\n",
    "    cursor.execute(f\"SET search_path TO {schema_name};\")\n",
    "    cursor.close()\n",
    "# with conn.cursor() as cur:\n",
    "#     cur.execute(f\"SET search_path TO {schema_name};\")\n",
    "\n",
    "# Define a default JSON object for fields that are None\n",
    "default_json = {}  # Update this with a suitable default JSON object\n",
    "empty_placeholder = \"\\\\N\"  # Placeholder for empty fields in .dump file\n",
    "\n",
    "with engine.connect() as conn:\n",
    "        print(\"Successfully connected to the database!\")\n",
    "        conn.execute(text(f\"SET search_path TO {schema_name};\"))\n",
    "def export_table_data(query, params, connections, common_dump_file_name, schema_name, table_name, export_format='text', export_path='/app/outputs', log_file_name='query_log.txt',tables_file='tables_log.txt', CHUNK_SIZE=10000):\n",
    "    if not os.path.exists(export_path):\n",
    "        os.makedirs(export_path)\n",
    "\n",
    "    log_file_path = os.path.join(export_path, log_file_name)\n",
    "    dump_file_path = os.path.join(export_path, f\"{common_dump_file_name}.csv\")\n",
    "    tables_file_path = os.path.join(export_path, tables_file)\n",
    "\n",
    "    with open(log_file_path, 'a', encoding='utf-8') as log_file:\n",
    "        # Convert the query object to a string\n",
    "        query_str = str(query)\n",
    "\n",
    "        # Manually replace the parameter placeholder with its value\n",
    "        # Use repr() to handle string parameters correctly by adding quotes\n",
    "        param_value = repr(params['key_value']) if isinstance(params['key_value'], str) else str(params['key_value'])\n",
    "        query_str_with_params = query_str.replace(\":key_value\", param_value)\n",
    "\n",
    "        # Write the modified query to the log file\n",
    "        log_file.write(f\"Table: {table_name}\\n{query_str_with_params}\\n\")\n",
    "\n",
    "    with open(tables_file_path, 'a', encoding='utf-8') as tables_file:\n",
    "        # Write the modified query to the log file\n",
    "        #log_file.write(f\"{query_str_with_params}\\n\")\n",
    "        tables_file.write(f\"Table: {table_name}\\n\")\n",
    "  \n",
    "    with engine.connect() as connection:\n",
    "        try:\n",
    "            first_chunk = True\n",
    "            print(f\"running for table -> {table_name} chunks with params {params} ----the query {query}\")\n",
    "            for chunk in pd.read_sql_query(query, connection, params=params, chunksize=CHUNK_SIZE):\n",
    "                if first_chunk:\n",
    "                    # Write column names and COPY command only for the first chunk\n",
    "                    column_names = '\\t '.join(chunk.columns)\n",
    "                    header_str = f\"{schema_name}.{table_name}\\n{column_names}\\n\"  # Removed the closing parenthesis\n",
    "                    first_chunk = False\n",
    "                else:\n",
    "                    header_str = ''\n",
    "\n",
    "                chunk.dropna(how='all', inplace=True)\n",
    "\n",
    "                # Convert the DataFrame to a CSV formatted string\n",
    "                csv_string = chunk.to_csv(sep='\\t', index=False, header=False)\n",
    "\n",
    "                # Append the header and CSV string to the dump file\n",
    "                with open(dump_file_path, 'a', encoding='utf-8') as dump_file:\n",
    "                    dump_file.write(header_str + csv_string)\n",
    "\n",
    "            # # Write the end-of-data marker\n",
    "            with open(dump_file_path, 'a', encoding='utf-8') as dump_file:\n",
    "                dump_file.write(\"\\n\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "\n",
    "    print(f\"Data appended to {dump_file_path} with query logged in {log_file_path}\")\n",
    "\n",
    "    \n",
    "\n",
    "def generate_truncate_sql(export_path, related_tables):\n",
    "    truncate_file_path = os.path.join(export_path, \"truncate_tables.sql\")\n",
    "    with open(truncate_file_path, 'w', encoding='utf-8') as truncate_file:\n",
    "        for table in related_tables:\n",
    "            truncate_file.write(f\"TRUNCATE TABLE {schema_name}.{table} restart identity cascade;\\n\")\n",
    "    print(f\"Truncate script created at {truncate_file_path}\")\n",
    "\n",
    "\n",
    "def get_key_value(table, column, value, connection):\n",
    "    \"\"\"\n",
    "    Fetch the corresponding key value from a table based on a column and its value.\n",
    "    \"\"\"\n",
    "    query = f\"SELECT {column} FROM {table} WHERE {column} = %s;\"\n",
    "    with connection.cursor() as cur:\n",
    "        cur.execute(query, [value])\n",
    "        result = cur.fetchone()\n",
    "        return result[0] if result else None\n",
    "\n",
    "\n",
    "\n",
    "def find_related_tables_bfs(engine, starting_table, start_table_key_column, key_value, common_dump_file_name, schema_name, excluded_tables=None, excluded_columns=None):\n",
    "    if excluded_tables is None:\n",
    "        excluded_tables = set()\n",
    "    if excluded_columns is None:\n",
    "        excluded_columns = {'modified_by_id', 'created_by_id'}\n",
    "\n",
    "    queue = deque([(starting_table, '')])\n",
    "    visited = set()\n",
    "\n",
    "    while queue:\n",
    "        current_table, previous_joins = queue.popleft()\n",
    "\n",
    "        where_clause = f'WHERE \"{schema_name}\".\"{starting_table}\".\"{start_table_key_column}\" = :key_value'\n",
    "       \n",
    "        if current_table == starting_table:\n",
    "            visited.add(current_table)\n",
    "            initial_query_str = f'SELECT DISTINCT * FROM \"{schema_name}\".\"{current_table}\"  WHERE \"{schema_name}\".\"{starting_table}\".\"{start_table_key_column}\" = :key_value'\n",
    "            # Convert the string query to a SQLAlchemy text object\n",
    "            initial_query = text(initial_query_str)\n",
    "            with engine.connect() as conn:\n",
    "                export_table_data(initial_query, {'key_value': key_value}, conn, common_dump_file_name, schema_name, current_table, export_format='text')\n",
    "\n",
    "        foreign_key_query = \"\"\"\n",
    "        SELECT DISTINCT\n",
    "            tc.table_name AS primary_table, \n",
    "            kcu.column_name AS primary_column, \n",
    "            ccu.table_name AS foreign_table_name,\n",
    "            ccu.column_name AS foreign_column\n",
    "        FROM \n",
    "            information_schema.table_constraints AS tc \n",
    "            JOIN information_schema.key_column_usage AS kcu \n",
    "            ON tc.constraint_name = kcu.constraint_name\n",
    "            JOIN information_schema.constraint_column_usage AS ccu \n",
    "            ON ccu.constraint_name = tc.constraint_name\n",
    "        WHERE \n",
    "            tc.constraint_type = 'FOREIGN KEY' AND \n",
    "            (tc.table_name = :current_table OR ccu.table_name = :current_table);\n",
    "        \"\"\"\n",
    "        print(f\"Current to process table  TO {current_table} previous JOINS joins: {previous_joins}\")\n",
    "        with engine.connect() as conn:\n",
    "            result = conn.execute(sqlalchemy.text(foreign_key_query), {'current_table': current_table})\n",
    "            rows = result.fetchall()\n",
    "            print(f\"Current to process table  TO {current_table} previous RESULTS FETCHED: {rows}\")\n",
    "            for row in rows:\n",
    "                primary_table, primary_column, foreign_table_name, foreign_column = row\n",
    "\n",
    "                \n",
    "                print(f\"Current to process table  TO {current_table} prIMARY: {primary_table}, COL {primary_column} foreign {foreign_table_name} col {foreign_column}\")\n",
    "                # Skip processing for excluded columns\n",
    "                if primary_column in excluded_columns or foreign_column in excluded_columns:\n",
    "                    print(f\"SKIIIIIIIIIIIIIIIIIIIIIP\")\n",
    "                    continue\n",
    "                if primary_table != current_table: \n",
    "                # Usage of construct_join_query in your code\n",
    "                    if primary_table not in visited and primary_table not in excluded_tables:\n",
    "                        new_join_condition = f'LEFT JOIN \\\"{schema_name}\\\".\\\"{primary_table}\\\" ON \\\"{schema_name}\\\".\\\"{foreign_table_name}\\\".\\\"{foreign_column}\\\" = \\\"{schema_name}\\\".\\\"{primary_table}\\\".\\\"{primary_column}\\\"'\n",
    "                        #full_join_query = construct_join_query(schema_name, foreign_table_name, primary_table, foreign_column, primary_column, key_value, previous_joins, where_clause)\n",
    "                        full_join_query =  f\"SELECT DISTINCT \\\"{schema_name}\\\".\\\"{primary_table}\\\".* FROM \\\"{schema_name}\\\".\\\"{starting_table}\\\"  {previous_joins}  {new_join_condition} {where_clause} AND \\\"{schema_name}\\\".\\\"{primary_table}\\\".\\\"{primary_column}\\\" IS NOT NULL\"\n",
    "                        \n",
    "                        export_table_data(full_join_query, {'key_value': key_value}, conn, common_dump_file_name, schema_name, primary_table, export_format='text')\n",
    "                        next_joins = f\"{previous_joins} {new_join_condition}\"\n",
    "                        print(f\"APPENDING TO {primary_table} next joins: {next_joins}\")\n",
    "                        queue.append((primary_table, next_joins))\n",
    "                        visited.add(primary_table)\n",
    "                        \n",
    "                elif foreign_table_name != current_table:\n",
    "                    if foreign_table_name not in visited and foreign_table_name not in excluded_tables:\n",
    "                        new_join_condition = f'LEFT JOIN \\\"{schema_name}\\\".\\\"{foreign_table_name}\\\" ON \\\"{schema_name}\\\".\\\"{primary_table}\\\".\\\"{primary_column}\\\" = \\\"{schema_name}\\\".\\\"{foreign_table_name}\\\".\\\"{foreign_column}\\\"'\n",
    "                        #full_join_query = construct_join_query(schema_name, primary_table, foreign_table_name, primary_column, foreign_column, key_value, previous_joins, where_clause)\n",
    "                        full_join_query =  f\"SELECT DISTINCT \\\"{schema_name}\\\".\\\"{foreign_table_name}\\\".* FROM \\\"{schema_name}\\\".\\\"{starting_table}\\\" {previous_joins} {new_join_condition} {where_clause} AND \\\"{schema_name}\\\".\\\"{foreign_table_name}\\\".\\\"{foreign_column}\\\" IS NOT NULL\"\n",
    "                        export_table_data(full_join_query, {'key_value': key_value}, conn, common_dump_file_name, schema_name, foreign_table_name, export_format='text')\n",
    "                        next_joins = f\"{previous_joins} {new_join_condition}\"\n",
    "                        print(f\"APPENDING TO {foreign_table_name} next joins: {next_joins}\")\n",
    "                        queue.append((foreign_table_name, next_joins))\n",
    "                        visited.add(foreign_table_name)\n",
    "                    # Process each foreign key relationship\n",
    "                    # Your existing logic for handling relationships goes here\n",
    "\n",
    "    #return visited  # Optionally return the visited set for further analysis\n",
    "    return visited  # Optionally return the visited set for further analysis\n",
    "\n",
    "# Usage example\n",
    "common_dump_file_name = \"brands_dump\"\n",
    "# Retrieve script parameters from environment variables\n",
    "\n",
    "db_params = {\n",
    "    'host': os.getenv('DB_HOST', 'default_host'),\n",
    "    'dbname': os.getenv('DB_NAME', 'default_db_name'),\n",
    "    'user': os.getenv('DB_USER', 'default_user'),\n",
    "    'password': os.getenv('DB_PASSWORD', 'default_password'),\n",
    "    'port': int(os.getenv('DB_PORT', '5432'))  # Default port number if not specified\n",
    "}\n",
    "\n",
    "\n",
    "starting_table = os.getenv('STARTING_TABLE', 'default_value_for_starting_table')\n",
    "starting_key_column = os.getenv('STARTING_KEY_COLUMN', 'default_value_for_starting_key_column')\n",
    "\n",
    "# For 'key_value', handle different data types (string/int)\n",
    "key_value_str = os.getenv('KEY_VALUE', 'default_value_for_key_value')\n",
    "try:\n",
    "    key_value = int(key_value_str)\n",
    "except ValueError:\n",
    "    key_value = key_value_str  # Use the string value if it's not an integer\n",
    "\n",
    "# Split the excluded tables into a list if they are provided as a comma-separated string\n",
    "excluded_tables_str = os.getenv('EXCLUDED_TABLES', '')\n",
    "excluded_tables = excluded_tables_str.split(',') if excluded_tables_str else []\n",
    "\n",
    "# Global chunk size for data processing\n",
    "CHUNK_SIZE = 10000  # You can adjust this value as needed\n",
    "print(\"Hierarchy starting from '{}', for key '{}': {}\".format(starting_table, starting_key_column, key_value))\n",
    "related_tables = find_related_tables_bfs(engine,starting_table, starting_key_column, key_value, common_dump_file_name, schema_name, excluded_tables=excluded_tables)\n",
    "#def find_related_tables_bfs(engine, starting_table, start_table_key_column, key_value, common_dump_file_name, schema_name, excluded_tables=None, excluded_columns=None):\n",
    "  \n",
    "print(f\"Related tables: {related_tables}\")\n",
    "\n",
    "\n",
    "# Specify the file path where you want to save the output\n",
    "output_file_path = '/app/exports/related_tables_output.txt'\n",
    "\n",
    "# Writing the related tables to a file\n",
    "with open(output_file_path, 'w') as file:\n",
    "    for table in related_tables:\n",
    "        file.write(f\"{table}\\n\")\n",
    "\n",
    "print(f\"Related tables have been written to {output_file_path}\")\n",
    "\n",
    "generate_truncate_sql('/app/exports/', related_tables)\n",
    "#engine.dispose()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
